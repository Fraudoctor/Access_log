{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BigQuery settings\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import dbapi;\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the experience data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 2)\n"
     ]
    }
   ],
   "source": [
    "X1 = np.load('features/user_exp_score.npy').reshape((-1,1))\n",
    "X2 = np.load('features/avg_user_joint_exp.npy').reshape((-1,1))\n",
    "\n",
    "Y = np.load('features/t2tpa.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the busyness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 3)\n",
      "['JCcd691a' '131018562095' '39']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 3)\n",
      "['JCcb69cc' '131029086038' '125.33333333333333']\n",
      "131042907349\n",
      "131014276335\n",
      "131014194983\n",
      "131009784135\n"
     ]
    }
   ],
   "source": [
    "# load the patient enc id:\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import dbapi;\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "query = \"select jc_uid, pat_enc_csn_id_coded, t2tpa from `noshad.cohort_v2`\"; # Example dataset table\n",
    "cursor.execute(query);\n",
    "results = cursor.fetchall();\n",
    "\n",
    "A = np.array(results)\n",
    "print(A.shape)\n",
    "print(A[0,:])\n",
    "Enc_ID = A[:,1]  \n",
    "\n",
    "\n",
    "# Create the distionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pat_dic = {}\n",
    "\n",
    "for id in Enc_ID:\n",
    "    #print(id)\n",
    "    #print(np.where(A[:,1]==id)[0])\n",
    "    #print(A[np.where(A[:,1]==id)[0],2])\n",
    "    t2tpa = int(A[np.where(A[:,1]==id)[0],2])\n",
    "    pat_id = A[np.where(A[:,1]==id)[0],0]\n",
    "    \n",
    "    #print(t2tpa)\n",
    "    if t2tpa < 60*10:\n",
    "        Pat_dic[id] = {} #each patient has a dictionary\n",
    "        Pat_dic[id]['t2tpa'] = t2tpa\n",
    "        Pat_dic[id]['pat_id'] = pat_id\n",
    "\n",
    "\n",
    "\n",
    "# Extract all action busyness:\n",
    "\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "query = \"select jc_uid, pat_enc_csn_id_coded, dep_busy_norm_all_actions from `noshad.Feature_dep_busy_all_actions`\"; # Example dataset table\n",
    "cursor.execute(query);\n",
    "results = cursor.fetchall();\n",
    "\n",
    "A = np.array(results)\n",
    "print(A.shape)\n",
    "print(A[0,:])\n",
    "\n",
    "\n",
    "#with open('features/num_tnx.csv', 'r') as f:\n",
    "#    A_temp = csv.reader(f)\n",
    "#    temp = list(A_temp)\n",
    "\n",
    "#print(temp[0]) # The column names\n",
    "\n",
    "#A = np.array(temp[1:]) # array of t2tpa\n",
    "\n",
    "\n",
    "for id in Pat_dic.keys():\n",
    "    if A[np.where(A[:,1]==id)[0],2].shape[0] > 0:\n",
    "        num_actions = float(A[np.where(A[:,1]==id)[0],2])\n",
    "        Pat_dic[id]['dep_busy_all_actions'] = num_actions\n",
    "    else:\n",
    "        print(id)\n",
    "        Pat_dic[id]['dep_busy_all_actions'] = 0\n",
    "\n",
    "\n",
    "        \n",
    "# Busyness to numpy\n",
    "X3 = np.array([Pat_dic[id]['dep_busy_all_actions'] for id in Pat_dic.keys()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data and split to train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 3)\n"
     ]
    }
   ],
   "source": [
    "# Replace Nan with -1:\n",
    "X1[np.isnan(X1[:,0])]= -1\n",
    "X2[np.isnan(X1[:,0])]= -1\n",
    "X3[np.isnan(X1[:,0])]= -1\n",
    "\n",
    "Y[np.isnan(X1[:,0])]= -1\n",
    "\n",
    "X = np.concatenate((X1, X2, X3.reshape((-1,1))), axis=1)\n",
    "N = X.shape[0]\n",
    "print(X.shape)\n",
    "\n",
    "# train and test\n",
    "\n",
    "N_train = 200\n",
    "\n",
    "X_train = X[:N_train,:]\n",
    "X_test = X[N_train:,:]\n",
    "\n",
    "Y_train = Y[:N_train]\n",
    "Y_test = Y[N_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.18000572961695\n",
      "Y statistics 56.208333333333336 38.6079528266476\n",
      "RBF:  [26.55389636 33.00544152 26.10358167 26.95047568 28.39020259] 28.20071956334372\n",
      "Linear:  [25.4184934  29.47047541 18.70258583 25.37941711 21.79451928] 24.153098206079868\n",
      "poly2:  [25.15527264 30.57775084 21.06519911 27.99958752 23.92649424] 25.74486086704557\n",
      "poly3:  [25.06532244 30.5149656  21.22246579 28.44417377 23.90586541] 25.83055860086778\n",
      "poly4:  [25.02566095 30.46416623 21.28476309 28.15490504 23.82040707] 25.749980476173857\n",
      "poly5:  [25.00433956 30.09979739 21.24549392 29.76741303 23.73030411] 25.96946960198274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto')\n",
    "svr_poly2 = SVR(kernel='poly', degree=2)#, C=100, gamma='auto', degree=4)\n",
    "svr_poly3 = SVR(kernel='poly', degree=3)#, C=100, gamma='auto', degree=4)\n",
    "svr_poly4 = SVR(kernel='poly', degree=4)#, C=100, gamma='auto', degree=4)\n",
    "svr_poly5 = SVR(kernel='poly', degree=5)#, C=100, gamma='auto', degree=4)\n",
    "\n",
    "\n",
    "Y_pred = svr_poly.fit(X_train, Y_train).predict(X_test)\n",
    "print(np.mean(Y_pred))\n",
    "\n",
    "\n",
    "print('Y statistics',np.mean(Y), np.std(Y))\n",
    "#clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(svr_rbf, X, Y, cv=5, scoring='neg_mean_absolute_error') #scoring = 'neg_mean_absolute_error')\n",
    "print('RBF: ',-scores, np.mean(-scores))\n",
    "\n",
    "scores = cross_val_score(svr_lin, X, Y, cv=5, scoring='neg_mean_absolute_error') #scoring = 'neg_mean_absolute_error')\n",
    "print('Linear: ',-scores, np.mean(-scores))\n",
    "\n",
    "scores = cross_val_score(svr_poly2, X, Y, cv=5, scoring='neg_mean_absolute_error') #scoring = 'neg_mean_absolute_error')\n",
    "print('poly2: ',-scores, np.mean(-scores))\n",
    "\n",
    "scores = cross_val_score(svr_poly3, X, Y, cv=5, scoring='neg_mean_absolute_error') #scoring = 'neg_mean_absolute_error')\n",
    "print('poly3: ',-scores, np.mean(-scores))\n",
    "scores = cross_val_score(svr_poly4, X, Y, cv=5, scoring='neg_mean_absolute_error') #scoring = 'neg_mean_absolute_error')\n",
    "print('poly4: ',-scores, np.mean(-scores))\n",
    "scores = cross_val_score(svr_poly5, X, Y, cv=5, scoring='neg_mean_absolute_error') #scoring = 'neg_mean_absolute_error')\n",
    "print('poly5: ',-scores, np.mean(-scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4446228363625163, 0.0002324858484278026)\n",
      "(0.3147235471223256, 0.01131274097923752)\n",
      "(0.2924594153637401, 0.019022603410975312)\n",
      "(0.3366525101612707, 0.006527626011233836)\n",
      "(0.31780921200594053, 0.010494807795011397)\n",
      "(0.093667571180747, 0.4616135728404382)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from scipy.stats.stats import pearsonr \n",
    "\n",
    "\n",
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto')\n",
    "svr_poly2 = SVR(kernel='poly', degree=2)#, C=100, gamma='auto', degree=4)\n",
    "svr_poly3 = SVR(kernel='poly', degree=3)#, C=100, gamma='auto', degree=4)\n",
    "svr_poly4 = SVR(kernel='poly', degree=4)#, C=100, gamma='auto', degree=4)\n",
    "svr_poly5 = SVR(kernel='poly', degree=5)#, C=100, gamma='auto', degree=4)\n",
    "\n",
    "\n",
    "Y_pred = svr_lin.fit(X_train, Y_train).predict(X_test)\n",
    "#print(np.mean(Y_pred))\n",
    "print(pearsonr(np.reshape(Y_pred,(-1,)), np.reshape((Y_test),(-1,))))\n",
    "\n",
    "Y_pred = svr_poly2.fit(X_train, Y_train).predict(X_test)\n",
    "#print(np.mean(Y_pred))\n",
    "print(pearsonr(np.reshape(Y_pred,(-1,)), np.reshape((Y_test),(-1,))))\n",
    "\n",
    "Y_pred = svr_poly3.fit(X_train, Y_train).predict(X_test)\n",
    "#print(np.mean(Y_pred))\n",
    "print(pearsonr(np.reshape(Y_pred,(-1,)), np.reshape((Y_test),(-1,))))\n",
    "\n",
    "Y_pred = svr_poly4.fit(X_train, Y_train).predict(X_test)\n",
    "#print(np.mean(Y_pred))\n",
    "print(pearsonr(np.reshape(Y_pred,(-1,)), np.reshape((Y_test),(-1,))))\n",
    "\n",
    "Y_pred = svr_poly5.fit(X_train, Y_train).predict(X_test)\n",
    "#print(np.mean(Y_pred))\n",
    "print(pearsonr(np.reshape(Y_pred,(-1,)), np.reshape((Y_test),(-1,))))\n",
    "\n",
    "Y_pred = svr_rbf.fit(X_train, Y_train).predict(X_test)\n",
    "#print(np.mean(Y_pred))\n",
    "print(pearsonr(np.reshape(Y_pred,(-1,)), np.reshape((Y_test),(-1,))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_pred = svr_rbf.fit(X_train, Y_train).predict(X_test)\n",
    "print(np.mean(Y_pred))\n",
    "\n",
    "r = svr_rbf.fit(X_train, Y_train).score(X_test,Y_test)\n",
    "print(r)\n",
    "print(svr_rbf.fit(X_train, Y_train).predict(X_test)[:20])\n",
    "print(Y_test[:20])\n",
    "print('MSE',np.sqrt(MSE(Y_test, Y_pred)))\n",
    "\n",
    "\n",
    "print(scores)\n",
    "print(Y[:20])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
