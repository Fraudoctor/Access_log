{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BigQuery settings\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import dbapi;\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# ignore if local tmp.csv already exists in the time_mapping folder. We need this to identify the dates\n",
    "# read the time matching CSV and remove MRNs for security reasons (ignore if local tmp.csv already exists)\n",
    "import pandas as pd\n",
    "data_frame = pd.read_csv('time_mapping/jon_mapping.csv')\n",
    "data_frame = data_frame.drop('MRN', axis = 1) \n",
    "data_frame.to_csv('time_mapping/tmp.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a table of ADT of cohort patients (with jittered times) (ADT_cohort_jit) in order to find all the patients at the same department during the diagnostic process**\n",
    "\n",
    "*Skip if table ADT_cohort_jit already exists on GCP*\n",
    "\n",
    "**Remark:** time_out is either the actual time_out or TPA_admin_time, whichever is earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query =  \"\"\"\n",
    "drop table if exists noshad.ADT_cohort_jit;\n",
    "create table noshad.ADT_cohort_jit as\n",
    "(\n",
    "SELECT ADT.jc_uid, ADT.pat_enc_csn_id_coded, ADT.department_id, CH.tpaAdminTime,\n",
    "    min(ADT.event_time_jittered) AS time_in, max(ADT.event_time_jittered) AS time_out\n",
    "FROM `starr_datalake2018.adt` AS ADT\n",
    "INNER JOIN `noshad.cohort_v2` AS CH\n",
    "  USING (pat_enc_csn_id_coded)\n",
    "GROUP BY ADT.jc_uid, ADT.pat_enc_csn_id_coded, ADT.department_id, CH.tpaAdminTime\n",
    "ORDER BY ADT.jc_uid, ADT.pat_enc_csn_id_coded, time_in\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(query);\n",
    "\n",
    "#results = cursor.fetchall();\n",
    "#print(results[:2])\n",
    "#results_np = np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature: Department Busyness all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary tmp file generated\n",
      "feature extraced\n",
      "temporary tmp file deleted\n"
     ]
    }
   ],
   "source": [
    "## main part to generate the transaction rate associated with other patients per each cohort_patient\n",
    "# CREATE OR REPLACE TABLE noshad.Feature_dep_busy_all_actions\n",
    "\n",
    "\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "\n",
    "# Upload time_mapping tmp.CSV \n",
    "\n",
    "schemafield_col1 = bigquery.schema.SchemaField(\"ANON_ID\",\"STRING\") #Define your schema\n",
    "schemafield_col2 = bigquery.schema.SchemaField(\"JITTER\",\"INTEGER\")\n",
    "\n",
    "filename = 'time_mapping/tmp.csv'\n",
    "table_id = 'tmp' # the name of the chart to create\n",
    "\n",
    "dataset_ref = client.dataset('noshad')\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print('temporary tmp file generated')\n",
    "\n",
    "# Main part to generate num_pat per each patient\n",
    "query= \"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE noshad.Feature_dep_busy_all_actions as (\n",
    "WITH\n",
    "\n",
    "    -- Generate ADT_cohort with actual times and only ED (almost the same rows as the cohort table but also with ADT info)\n",
    "  ADT_real_date AS\n",
    "  (SELECT ADT.* except(time_in,time_out,tpaAdminTime), DATETIME_SUB(ADT.time_in, INTERVAL TMP.JITTER DAY) as time_in,  \n",
    "  DATETIME_SUB(ADT.time_out, INTERVAL TMP.JITTER DAY) as time_out, \n",
    "  DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY) as tpaAdminTime,\n",
    "  DATETIME_SUB(DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_before,\n",
    "  DATETIME_ADD(DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_after,\n",
    "  EXTRACT(DATE FROM DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY)) as tpa_date\n",
    "  \n",
    "  FROM `noshad.ADT_cohort_jit` as ADT,\n",
    "  `noshad.tmp` as TMP\n",
    "  \n",
    "  WHERE ADT.jc_uid=TMP.ANON_ID\n",
    "    AND ADT.department_id = 2001002\n",
    "    AND time_in < tpaAdminTime\n",
    "  ),\n",
    "  \n",
    "  \n",
    "    -- Generate AL with actual times\n",
    "  AL_real_date AS\n",
    "  (SELECT AL.*, \n",
    "      DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real,\n",
    "      EXTRACT(DATE FROM DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY)) as access_date\n",
    "  FROM `noshad.shc_access_log_de_dep_id` as AL,\n",
    "  `noshad.tmp` as TMP\n",
    "  WHERE AL.rit_uid=TMP.ANON_ID\n",
    "    AND AL.department_id = 2001002\n",
    "  )\n",
    "  \n",
    "\n",
    "    SELECT ADT_real_date.jc_uid, ADT_real_date.pat_enc_csn_id_coded, count(*) as dep_busy_all_actions, \n",
    "\n",
    "    FROM  ADT_real_date INNER JOIN AL_real_date on (tpa_date=access_date)\n",
    "\n",
    "    WHERE \n",
    "\n",
    "        AL_real_date.access_time_real BETWEEN ADT_real_date.tpa_60_before AND ADT_real_date.tpa_60_after \n",
    "        \n",
    "    GROUP By ADT_real_date.jc_uid, ADT_real_date.pat_enc_csn_id_coded\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query);\n",
    "\n",
    "print('feature extraced')\n",
    "\n",
    "## Final step: delete the temporary time mapping\n",
    "query = \"DROP TABLE noshad.tmp\"\n",
    "cursor.execute(query);\n",
    "\n",
    "print('temporary tmp file deleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature: Department Busyness all_clinical_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary tmp file generated\n",
      "feature extraced\n",
      "temporary tmp file deleted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CREATE OR REPLACE TABLE noshad.Feature_dep_busy_clinical_actions\n",
    "\n",
    "\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "\n",
    "# Upload time_mapping tmp.CSV \n",
    "\n",
    "schemafield_col1 = bigquery.schema.SchemaField(\"ANON_ID\",\"STRING\") #Define your schema\n",
    "schemafield_col2 = bigquery.schema.SchemaField(\"JITTER\",\"INTEGER\")\n",
    "\n",
    "filename = 'time_mapping/tmp.csv'\n",
    "table_id = 'tmp' # the name of the chart to create\n",
    "\n",
    "dataset_ref = client.dataset('noshad')\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print('temporary tmp file generated')\n",
    "\n",
    "# Main part to generate num_pat per each patient\n",
    "query= \"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE noshad.Feature_dep_busy_clinical_actions as (\n",
    "WITH\n",
    "\n",
    "    -- Generate ADT_cohort with actual times and only ED\n",
    "  ADT_real_date AS\n",
    "  (SELECT ADT.* except(time_in,time_out,tpaAdminTime), DATETIME_SUB(ADT.time_in, INTERVAL TMP.JITTER DAY) as time_in,  \n",
    "  DATETIME_SUB(ADT.time_out, INTERVAL TMP.JITTER DAY) as time_out, \n",
    "  DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY) as tpaAdminTime,\n",
    "  DATETIME_SUB(DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_before,\n",
    "  DATETIME_ADD(DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_after,\n",
    "  EXTRACT(DATE FROM DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY)) as tpa_date\n",
    "  \n",
    "  FROM `noshad.ADT_cohort_jit` as ADT,\n",
    "  `noshad.tmp` as TMP\n",
    "  \n",
    "  WHERE ADT.jc_uid=TMP.ANON_ID\n",
    "    AND ADT.department_id = 2001002\n",
    "      AND time_in < tpaAdminTime\n",
    "  ),\n",
    "  \n",
    "  \n",
    "    -- Generate AL with actual times with specific restrictions\n",
    "  AL_real_date AS\n",
    "  (SELECT AL.*, \n",
    "      DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real,\n",
    "      EXTRACT(DATE FROM DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY)) as access_date\n",
    "  FROM `noshad.shc_access_log_de_dep_id` as AL\n",
    "  LEFT JOIN `noshad.tmp` as TMP ON (AL.rit_uid=TMP.ANON_ID)\n",
    "  WHERE \n",
    "     AL.department_id = 2001002\n",
    "    AND \n",
    "    (\n",
    "    metric_name like \"%Lab%\" OR metric_name like \"%lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Report%\" OR metric_name like \"%report%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%Medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "\n",
    "    )\n",
    "  )\n",
    "  \n",
    "\n",
    "    SELECT ADT_real_date.jc_uid, ADT_real_date.pat_enc_csn_id_coded, count(*) as dep_busy_clinical_actions, \n",
    "\n",
    "    FROM  ADT_real_date INNER JOIN AL_real_date on (tpa_date=access_date)\n",
    "\n",
    "    WHERE \n",
    "\n",
    "        AL_real_date.access_time_real BETWEEN ADT_real_date.tpa_60_before AND ADT_real_date.tpa_60_after \n",
    "        \n",
    "    GROUP By ADT_real_date.jc_uid, ADT_real_date.pat_enc_csn_id_coded\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query);\n",
    "\n",
    "print('feature extraced')\n",
    "\n",
    "## Final step: delete the temporary time mapping\n",
    "query = \"DROP TABLE noshad.tmp\"\n",
    "cursor.execute(query);\n",
    "\n",
    "print('temporary tmp file deleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature: Department Busyness all_imaging_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary tmp file generated\n",
      "feature extraced\n",
      "temporary tmp file deleted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CREATE OR REPLACE TABLE noshad.Feature_dep_busy_imaging_actions\n",
    "\n",
    "\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "\n",
    "# Upload time_mapping tmp.CSV \n",
    "\n",
    "schemafield_col1 = bigquery.schema.SchemaField(\"ANON_ID\",\"STRING\") #Define your schema\n",
    "schemafield_col2 = bigquery.schema.SchemaField(\"JITTER\",\"INTEGER\")\n",
    "\n",
    "filename = 'time_mapping/tmp.csv'\n",
    "table_id = 'tmp' # the name of the chart to create\n",
    "\n",
    "dataset_ref = client.dataset('noshad')\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print('temporary tmp file generated')\n",
    "\n",
    "# Main part to generate num_pat per each patient\n",
    "query= \"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE noshad.Feature_dep_busy_imaging_actions as (\n",
    "WITH\n",
    "\n",
    "    -- Generate ADT_cohort with actual times and only ED\n",
    "  ADT_real_date AS\n",
    "  (SELECT ADT.* except(time_in,time_out,tpaAdminTime), DATETIME_SUB(ADT.time_in, INTERVAL TMP.JITTER DAY) as time_in,  \n",
    "  DATETIME_SUB(ADT.time_out, INTERVAL TMP.JITTER DAY) as time_out, \n",
    "  DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY) as tpaAdminTime,\n",
    "  DATETIME_SUB(DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_before,\n",
    "  DATETIME_ADD(DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_after,\n",
    "  EXTRACT(DATE FROM DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY)) as tpa_date\n",
    "  \n",
    "  FROM `noshad.ADT_cohort_jit` as ADT,\n",
    "  `noshad.tmp` as TMP\n",
    "  \n",
    "  WHERE ADT.jc_uid=TMP.ANON_ID\n",
    "    AND ADT.department_id = 2001002\n",
    "      AND time_in < tpaAdminTime\n",
    "  ),\n",
    "  \n",
    "  \n",
    "    -- Generate AL with actual times with specific restrictions\n",
    "  AL_real_date AS\n",
    "  (SELECT AL.*, \n",
    "      DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real,\n",
    "      EXTRACT(DATE FROM DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY)) as access_date\n",
    "  FROM `noshad.shc_access_log_de_dep_id` as AL\n",
    "  LEFT JOIN `noshad.tmp` as TMP ON (AL.rit_uid=TMP.ANON_ID)\n",
    "  WHERE \n",
    "     AL.department_id = 2001002\n",
    "    AND \n",
    "    (\n",
    "    metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "\n",
    "    )\n",
    "  )\n",
    "  \n",
    "\n",
    "    SELECT ADT_real_date.jc_uid, ADT_real_date.pat_enc_csn_id_coded, count(*) as dep_busy_imaging_actions, \n",
    "\n",
    "    FROM  ADT_real_date INNER JOIN AL_real_date on (tpa_date=access_date)\n",
    "\n",
    "    WHERE \n",
    "\n",
    "        AL_real_date.access_time_real BETWEEN ADT_real_date.tpa_60_before AND ADT_real_date.tpa_60_after \n",
    "        \n",
    "    GROUP By ADT_real_date.jc_uid, ADT_real_date.pat_enc_csn_id_coded\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query);\n",
    "\n",
    "print('feature extraced')\n",
    "\n",
    "## Final step: delete the temporary time mapping\n",
    "query = \"DROP TABLE noshad.tmp\"\n",
    "cursor.execute(query);\n",
    "\n",
    "print('temporary tmp file deleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature: Department Busyness num_active_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary tmp file generated\n",
      "feature extraced\n",
      "temporary tmp file deleted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CREATE OR REPLACE TABLE noshad.Feature_dep_busy_active_pat\n",
    "\n",
    "\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "\n",
    "# Upload time_mapping tmp.CSV \n",
    "\n",
    "schemafield_col1 = bigquery.schema.SchemaField(\"ANON_ID\",\"STRING\") #Define your schema\n",
    "schemafield_col2 = bigquery.schema.SchemaField(\"JITTER\",\"INTEGER\")\n",
    "\n",
    "filename = 'time_mapping/tmp.csv'\n",
    "table_id = 'tmp' # the name of the chart to create\n",
    "\n",
    "dataset_ref = client.dataset('noshad')\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print('temporary tmp file generated')\n",
    "\n",
    "# Main part to generate num_pat per each patient\n",
    "query= \"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE noshad.Feature_dep_busy_active_pat as (\n",
    "WITH\n",
    "\n",
    "    -- Generate ADT_cohort with actual times and only ED\n",
    "  ADT_real_date AS\n",
    "  (SELECT ADT.* except(time_in,time_out,tpaAdminTime), DATETIME_SUB(ADT.time_in, INTERVAL TMP.JITTER DAY) as time_in,  \n",
    "  DATETIME_SUB(ADT.time_out, INTERVAL TMP.JITTER DAY) as time_out, \n",
    "  DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY) as tpaAdminTime,\n",
    "  DATETIME_SUB(DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_before,\n",
    "  DATETIME_ADD(DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_after,\n",
    "  EXTRACT(DATE FROM DATETIME_SUB(ADT.tpaAdminTime, INTERVAL TMP.JITTER DAY)) as tpa_date\n",
    "  \n",
    "  FROM `noshad.ADT_cohort_jit` as ADT,\n",
    "  `noshad.tmp` as TMP\n",
    "  \n",
    "  WHERE ADT.jc_uid=TMP.ANON_ID\n",
    "    AND ADT.department_id = 2001002\n",
    "      AND time_in < tpaAdminTime\n",
    "  ),\n",
    "  \n",
    "  \n",
    "    -- Generate AL with actual times with specific restrictions\n",
    "  AL_real_date AS\n",
    "  (SELECT AL.*, \n",
    "      DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real,\n",
    "      EXTRACT(DATE FROM DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY)) as access_date\n",
    "  FROM `noshad.shc_access_log_de_dep_id` as AL\n",
    "  LEFT JOIN `noshad.tmp` as TMP ON (AL.rit_uid=TMP.ANON_ID)\n",
    "  WHERE \n",
    "     AL.department_id = 2001002\n",
    "    AND \n",
    "    (\n",
    "    metric_name like \"%Lab%\" OR metric_name like \"%lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Report%\" OR metric_name like \"%report%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%Medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "\n",
    "    )\n",
    "  )\n",
    "  \n",
    "\n",
    "    SELECT ADT_real_date.jc_uid, ADT_real_date.pat_enc_csn_id_coded, count(DISTINCT AL_real_date.rit_uid) as dep_busy_active_pat, \n",
    "\n",
    "    FROM  ADT_real_date INNER JOIN AL_real_date on (tpa_date=access_date)\n",
    "\n",
    "    WHERE \n",
    "\n",
    "        AL_real_date.access_time_real BETWEEN ADT_real_date.tpa_60_before AND ADT_real_date.tpa_60_after \n",
    "        \n",
    "    GROUP By ADT_real_date.jc_uid, ADT_real_date.pat_enc_csn_id_coded\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query);\n",
    "\n",
    "print('feature extraced')\n",
    "\n",
    "## Final step: delete the temporary time mapping\n",
    "query = \"DROP TABLE noshad.tmp\"\n",
    "cursor.execute(query);\n",
    "\n",
    "print('temporary tmp file deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
