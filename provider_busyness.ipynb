{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BigQuery settings\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import dbapi;\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# ignore if local tmp.csv already exists in the time_mapping folder. We need this to identify the dates\n",
    "# read the time matching CSV and remove MRNs for security reasons (ignore if local tmp.csv already exists)\n",
    "import pandas as pd\n",
    "data_frame = pd.read_csv('time_mapping/jon_mapping.csv')\n",
    "data_frame = data_frame.drop('MRN', axis = 1) \n",
    "data_frame.to_csv('time_mapping/tmp.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a table of ADT of cohort patients (with jittered times) (ADT_cohort_jit) in order to find all the patients at the same department during the diagnostic process**\n",
    "\n",
    "*Skip if table ADT_cohort_jit already exists on GCP*\n",
    "\n",
    "**Remark:** time_out is either the actual time_out or TPA_admin_time, whichever is earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query =  \"\"\"\n",
    "drop table if exists noshad.ADT_cohort_jit;\n",
    "create table noshad.ADT_cohort_jit as\n",
    "(\n",
    "SELECT ADT.jc_uid, ADT.pat_enc_csn_id_coded, ADT.department_id, CH.tpaAdminTime,\n",
    "    min(ADT.event_time_jittered) AS time_in, max(ADT.event_time_jittered) AS time_out\n",
    "FROM `starr_datalake2018.adt` AS ADT\n",
    "INNER JOIN `noshad.cohort_v2` AS CH\n",
    "  USING (pat_enc_csn_id_coded)\n",
    "GROUP BY ADT.jc_uid, ADT.pat_enc_csn_id_coded, ADT.department_id, CH.tpaAdminTime\n",
    "ORDER BY ADT.jc_uid, ADT.pat_enc_csn_id_coded, time_in\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(query);\n",
    "\n",
    "#results = cursor.fetchall();\n",
    "#print(results[:2])\n",
    "#results_np = np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature: Provider Busyness all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary tmp file generated\n",
      "feature extraced\n",
      "temporary tmp file deleted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CREATE OR REPLACE TABLE noshad.Feature_prov_busy_clinical_actions\n",
    "\n",
    "\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "\n",
    "# Upload time_mapping tmp.CSV \n",
    "\n",
    "schemafield_col1 = bigquery.schema.SchemaField(\"ANON_ID\",\"STRING\") #Define your schema\n",
    "schemafield_col2 = bigquery.schema.SchemaField(\"JITTER\",\"INTEGER\")\n",
    "\n",
    "filename = 'time_mapping/tmp.csv'\n",
    "table_id = 'tmp' # the name of the chart to create\n",
    "\n",
    "dataset_ref = client.dataset('noshad')\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print('temporary tmp file generated')\n",
    "\n",
    "\n",
    "query= \"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE noshad.Feature_prov_busy_all_actions as (\n",
    "WITH\n",
    "\n",
    "    -- Generate cohort table with actual times\n",
    "  CHT_real_date AS\n",
    "  (SELECT CHT.* except(tpaAdminTime), \n",
    "  DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY) as tpaAdminTime,\n",
    "  DATETIME_SUB(DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_before,\n",
    "  DATETIME_ADD(DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_after,\n",
    "  EXTRACT(DATE FROM DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY)) as tpa_date\n",
    "  \n",
    "  FROM `noshad.cohort_v2` as CHT,\n",
    "  `noshad.tmp` as TMP\n",
    "  \n",
    "  WHERE CHT.jc_uid=TMP.ANON_ID\n",
    "  \n",
    "  ),\n",
    "  \n",
    "  \n",
    "    -- Generate AL with actual times\n",
    "  AL_real_date AS\n",
    "  (SELECT AL.*, \n",
    "      DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real,\n",
    "      EXTRACT(DATE FROM DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY)) as access_date\n",
    "  FROM `noshad.shc_access_log_de_dep_id` as AL,\n",
    "  `noshad.tmp` as TMP\n",
    "  WHERE AL.rit_uid=TMP.ANON_ID\n",
    "    AND AL.department_id = 2001002\n",
    "    AND \n",
    "    (\n",
    "    metric_name like \"%Lab%\" OR metric_name like \"%lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Report%\" OR metric_name like \"%report%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%Medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "\n",
    "    )\n",
    "  ),\n",
    "  \n",
    "  Team_users as\n",
    "  (\n",
    "  SELECT CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid, count(*) as user_cohort_actions\n",
    "  FROM  CHT_real_date INNER JOIN AL_real_date ON (CHT_real_date.pat_enc_csn_id_coded= AL_real_date.csn)\n",
    "  WHERE AL_real_date.access_time_real BETWEEN CHT_real_date.tpa_60_before AND CHT_real_date.tpa_60_after \n",
    "  GROUP By CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid \n",
    "  ),\n",
    "  \n",
    "  Prov_busy as ( \n",
    "  \n",
    "    SELECT CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid, count(*) as user_all_actions, \n",
    "    FROM  CHT_real_date INNER JOIN AL_real_date on (tpa_date=access_date)\n",
    "    WHERE \n",
    "        AL_real_date.access_time_real BETWEEN CHT_real_date.tpa_60_before AND CHT_real_date.tpa_60_after \n",
    "    GROUP By CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid\n",
    "    )\n",
    "\n",
    "SELECT Team_users.jc_uid, Team_users.pat_enc_csn_id_coded, avg(Prov_busy.user_all_actions) as prov_busy_all_actions, count(Team_users.user_cohort_actions) as team_size\n",
    "    FROM  Team_users LEFT JOIN Prov_busy USING (pat_enc_csn_id_coded)\n",
    "    WHERE Team_users.user_deid = Prov_busy.user_deid\n",
    "    GROUP BY jc_uid, pat_enc_csn_id_coded\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query);\n",
    "\n",
    "print('feature extraced')\n",
    "\n",
    "## Final step: delete the temporary time mapping\n",
    "query = \"DROP TABLE noshad.tmp\"\n",
    "cursor.execute(query);\n",
    "\n",
    "print('temporary tmp file deleted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature: Provider Busyness specific_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary tmp file generated\n",
      "feature extraced\n",
      "temporary tmp file deleted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CREATE OR REPLACE TABLE noshad.Feature_prov_busy_specific_actions\n",
    "\n",
    "\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "\n",
    "# Upload time_mapping tmp.CSV \n",
    "\n",
    "schemafield_col1 = bigquery.schema.SchemaField(\"ANON_ID\",\"STRING\") #Define your schema\n",
    "schemafield_col2 = bigquery.schema.SchemaField(\"JITTER\",\"INTEGER\")\n",
    "\n",
    "filename = 'time_mapping/tmp.csv'\n",
    "table_id = 'tmp' # the name of the chart to create\n",
    "\n",
    "dataset_ref = client.dataset('noshad')\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print('temporary tmp file generated')\n",
    "\n",
    "\n",
    "query= \"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE noshad.Feature_prov_busy_specific_actions as (\n",
    "WITH\n",
    "\n",
    "    -- Generate cohort table with actual times\n",
    "  CHT_real_date AS\n",
    "  (SELECT CHT.* except(tpaAdminTime), \n",
    "  DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY) as tpaAdminTime,\n",
    "  DATETIME_SUB(DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_before,\n",
    "  DATETIME_ADD(DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_after,\n",
    "  EXTRACT(DATE FROM DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY)) as tpa_date\n",
    "  \n",
    "  FROM `noshad.cohort_v2` as CHT,\n",
    "  `noshad.tmp` as TMP\n",
    "  \n",
    "  WHERE CHT.jc_uid=TMP.ANON_ID\n",
    "  \n",
    "  ),\n",
    "  \n",
    "  \n",
    "    -- Generate AL with actual times\n",
    "  AL_real_date AS\n",
    "  (SELECT AL.*, \n",
    "      DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real,\n",
    "      EXTRACT(DATE FROM DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY)) as access_date\n",
    "  FROM `noshad.shc_access_log_de_dep_id` as AL,\n",
    "  `noshad.tmp` as TMP\n",
    "  WHERE AL.rit_uid=TMP.ANON_ID\n",
    "    AND AL.department_id = 2001002\n",
    "    AND \n",
    "    (\n",
    "    --metric_name like \"%Lab%\" OR metric_name like \"%lab%\"\n",
    "    --OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    --OR metric_name like \"%Report%\" OR metric_name like \"%report%\"\n",
    "    --OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Result%\" OR metric_name like \"%result%\"  \n",
    "    --OR metric_name like \"%Medications%\" OR metric_name like \"%Medications%\"\n",
    "    --OR metric_name like \"%MAR%\" \n",
    "    --OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    --OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "\n",
    "    )\n",
    "  ),\n",
    "  \n",
    "  Team_users as\n",
    "  (\n",
    "  SELECT CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid, count(*) as user_cohort_actions\n",
    "  FROM  CHT_real_date INNER JOIN AL_real_date ON (CHT_real_date.pat_enc_csn_id_coded= AL_real_date.csn)\n",
    "  WHERE AL_real_date.access_time_real BETWEEN CHT_real_date.tpa_60_before AND CHT_real_date.tpa_60_after \n",
    "  GROUP By CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid \n",
    "  ),\n",
    "  \n",
    "  Prov_busy as ( \n",
    "  \n",
    "    SELECT CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid, count(*) as user_all_actions, \n",
    "    FROM  CHT_real_date INNER JOIN AL_real_date on (tpa_date=access_date)\n",
    "    WHERE \n",
    "        AL_real_date.access_time_real BETWEEN CHT_real_date.tpa_60_before AND CHT_real_date.tpa_60_after \n",
    "    GROUP By CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid\n",
    "    )\n",
    "\n",
    "SELECT Team_users.jc_uid, Team_users.pat_enc_csn_id_coded, avg(Prov_busy.user_all_actions) as prov_busy_specific_actions, count(Team_users.user_cohort_actions) as team_size\n",
    "    FROM  Team_users LEFT JOIN Prov_busy USING (pat_enc_csn_id_coded)\n",
    "    WHERE Team_users.user_deid = Prov_busy.user_deid\n",
    "    GROUP BY jc_uid, pat_enc_csn_id_coded\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query);\n",
    "\n",
    "print('feature extraced')\n",
    "\n",
    "## Final step: delete the temporary time mapping\n",
    "query = \"DROP TABLE noshad.tmp\"\n",
    "cursor.execute(query);\n",
    "\n",
    "print('temporary tmp file deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract Feature: Provider Busyness num patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporary tmp file generated\n",
      "feature extraced\n",
      "temporary tmp file deleted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CREATE OR REPLACE TABLE noshad.Feature_prov_busy_num_pat\n",
    "\n",
    "\n",
    "client = bigquery.Client(\"som-nero-phi-jonc101\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "\n",
    "# Upload time_mapping tmp.CSV \n",
    "\n",
    "schemafield_col1 = bigquery.schema.SchemaField(\"ANON_ID\",\"STRING\") #Define your schema\n",
    "schemafield_col2 = bigquery.schema.SchemaField(\"JITTER\",\"INTEGER\")\n",
    "\n",
    "filename = 'time_mapping/tmp.csv'\n",
    "table_id = 'tmp' # the name of the chart to create\n",
    "\n",
    "dataset_ref = client.dataset('noshad')\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.autodetect = True\n",
    "\n",
    "with open(filename, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for table load to complete.\n",
    "\n",
    "print('temporary tmp file generated')\n",
    "\n",
    "\n",
    "query= \"\"\"\n",
    "\n",
    "CREATE OR REPLACE TABLE noshad.Feature_prov_busy_num_pat as (\n",
    "WITH\n",
    "\n",
    "    -- Generate cohort table with actual times\n",
    "  CHT_real_date AS\n",
    "  (SELECT CHT.* except(tpaAdminTime), \n",
    "  DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY) as tpaAdminTime,\n",
    "  DATETIME_SUB(DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_before,\n",
    "  DATETIME_ADD(DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY), INTERVAL 60 MINUTE) as tpa_60_after,\n",
    "  EXTRACT(DATE FROM DATETIME_SUB(CHT.tpaAdminTime, INTERVAL TMP.JITTER DAY)) as tpa_date\n",
    "  \n",
    "  FROM `noshad.cohort_v2` as CHT,\n",
    "  `noshad.tmp` as TMP\n",
    "  \n",
    "  WHERE CHT.jc_uid=TMP.ANON_ID\n",
    "  \n",
    "  ),\n",
    "  \n",
    "  \n",
    "    -- Generate AL with actual times\n",
    "  AL_real_date AS\n",
    "  (SELECT AL.*, \n",
    "      DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real,\n",
    "      EXTRACT(DATE FROM DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY)) as access_date\n",
    "  FROM `noshad.shc_access_log_de_dep_id` as AL,\n",
    "  `noshad.tmp` as TMP\n",
    "  WHERE AL.rit_uid=TMP.ANON_ID\n",
    "    AND AL.department_id = 2001002\n",
    "    AND \n",
    "    (\n",
    "    metric_name like \"%Lab%\" OR metric_name like \"%lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Report%\" OR metric_name like \"%report%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Result%\" OR metric_name like \"%result%\"  \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%Medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "\n",
    "    )\n",
    "  ),\n",
    "  \n",
    "  -- Find the clinical users associated with a patient\n",
    "  Team_users as\n",
    "  (\n",
    "  SELECT CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid, count(*) as user_cohort_actions\n",
    "  FROM  CHT_real_date INNER JOIN AL_real_date ON (CHT_real_date.pat_enc_csn_id_coded= AL_real_date.csn)\n",
    "  WHERE AL_real_date.access_time_real BETWEEN CHT_real_date.tpa_60_before AND CHT_real_date.tpa_60_after \n",
    "  GROUP By CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid \n",
    "  ),\n",
    "  \n",
    "  -- Find the provider busyness for all patients and all providers during the TPA admin time (60 min before and after)\n",
    "  Prov_busy as ( \n",
    "  \n",
    "    SELECT CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid, count(DISTINCT AL_real_date.rit_uid) as num_pat, \n",
    "    FROM  CHT_real_date INNER JOIN AL_real_date on (tpa_date=access_date)\n",
    "    WHERE \n",
    "        AL_real_date.access_time_real BETWEEN CHT_real_date.tpa_60_before AND CHT_real_date.tpa_60_after \n",
    "    GROUP By CHT_real_date.jc_uid, CHT_real_date.pat_enc_csn_id_coded, AL_real_date.user_deid\n",
    "    )\n",
    "\n",
    "SELECT Team_users.jc_uid, Team_users.pat_enc_csn_id_coded, avg(Prov_busy.num_pat) as prov_busy_num_pat, count(Team_users.user_cohort_actions) as team_size\n",
    "    FROM  Team_users LEFT JOIN Prov_busy USING (pat_enc_csn_id_coded)\n",
    "    WHERE Team_users.user_deid = Prov_busy.user_deid\n",
    "    GROUP BY jc_uid, pat_enc_csn_id_coded\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query);\n",
    "\n",
    "print('feature extraced')\n",
    "\n",
    "## Final step: delete the temporary time mapping\n",
    "query = \"DROP TABLE noshad.tmp\"\n",
    "cursor.execute(query);\n",
    "\n",
    "print('temporary tmp file deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
